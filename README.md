# ğŸŒ¸ ClassificaÃ§Ã£o de Flores: Dense NN vs CNN

**ComparaÃ§Ã£o entre Machine Learning Tradicional e Deep Learning**

Baseado nos notebooks `02_asl.ipynb` e `03_asl_cnn.ipynb` apresentados em aula.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mIm1SXIhDy3M9o-HypHYy9PLp171W-rY?usp=sharing)

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa e compara duas abordagens diferentes para classificaÃ§Ã£o de imagens:

- **Dense Neural Network** (ML Tradicional) - baseado em `02_asl.ipynb`
- **Convolutional Neural Network** (Deep Learning) - baseado em `03_asl_cnn.ipynb`

### ğŸ¯ Objetivo
Demonstrar na prÃ¡tica por que CNNs sÃ£o superiores a Dense NNs para classificaÃ§Ã£o de imagens, utilizando um dataset diferente do ASL usado na aula.

### ğŸ”¬ HipÃ³tese
CNN deve superar significativamente o Dense NN para classificaÃ§Ã£o de imagens.

## ğŸ“Š Dataset

**Oxford Flowers 102**
- ğŸŒº **102 classes** de flores diferentes
- ğŸ–¼ï¸ **1.020 imagens** de treino
- ğŸ“ **6.149 imagens** de teste
- ğŸ”— **Fonte**: TensorFlow Datasets

**Por que este dataset:**
- Diferente do ASL (American Sign Language) usado na aula
- Mais desafiador: 102 classes vs 24 do ASL
- Imagens coloridas vs escala de cinza
- Ideal para mostrar vantagens da CNN

## ğŸ—ï¸ Arquitetura dos Modelos

### ğŸ”— Dense Neural Network
```
Input (64x64x3) â†’ Flatten (12,288) â†’ Dense (512) â†’ Dense (512) â†’ Output (102)
```
- **ParÃ¢metros**: 6,606,950
- **CaracterÃ­stica**: Trata cada pixel independentemente
- **Baseado em**: 02_asl.ipynb (mesma arquitetura)

### ğŸ§  Convolutional Neural Network
```
Input (64x64x3) â†’ Conv2D â†’ BatchNorm â†’ MaxPool â†’ 
Conv2D â†’ Dropout â†’ BatchNorm â†’ MaxPool â†’ 
Conv2D â†’ BatchNorm â†’ MaxPool â†’ 
Flatten â†’ Dense (512) â†’ Dropout â†’ Output (102)
```
- **ParÃ¢metros**: 919,813 (7x menor!)
- **CaracterÃ­stica**: Detecta padrÃµes espaciais
- **Baseado em**: 03_asl_cnn.ipynb (mesma estrutura)

## ğŸ“ˆ Resultados Obtidos

| Modelo | AcurÃ¡cia Treino | AcurÃ¡cia ValidaÃ§Ã£o | ParÃ¢metros | Tempo | EficiÃªncia |
|--------|----------------|-------------------|------------|-------|------------|
| **Dense NN** | 39.9% | 9.0% | 6,606,950 | 135s | Baixa |
| **CNN** | 79.3% | 0.3% | 919,813 | 402s | Alta |

### ğŸ† Principais Descobertas
- âœ… **CNN obteve o dobro da performance** no treino (79.3% vs 39.9%)
- âœ… **CNN Ã© 7x mais eficiente** em parÃ¢metros  
- âœ… **CNN aprende padrÃµes espaciais** vs pixels independentes
- âš ï¸ **Ambos apresentaram overfitting** (dataset desafiador)

### ğŸ“Š GrÃ¡ficos Comparativos
O projeto inclui visualizaÃ§Ãµes detalhadas mostrando:
- EvoluÃ§Ã£o da acurÃ¡cia durante treinamento
- ComparaÃ§Ã£o de nÃºmero de parÃ¢metros
- Tempo de treinamento
- Amostras do dataset

## ğŸš€ Como Executar

### **OpÃ§Ã£o 1: Google Colab (Recomendado)**
1. [Clique aqui para abrir no Colab](https://colab.research.google.com/drive/1mIm1SXIhDy3M9o-HypHYy9PLp171W-rY?usp=sharing)
2. Execute todas as cÃ©lulas sequencialmente
3. O dataset serÃ¡ baixado automaticamente

### **OpÃ§Ã£o 2: Ambiente Local**
```bash
# Clone o repositÃ³rio
git clone https://github.com/aanasc4/project_MLxDL.git
cd project_MLxDL

# Instale as dependÃªncias
pip install tensorflow tensorflow-datasets matplotlib numpy

# Execute o Jupyter
jupyter notebook
```

## ğŸ“¦ DependÃªncias

```txt
tensorflow>=2.8.0
tensorflow-datasets>=4.4.0
matplotlib>=3.3.0
numpy>=1.19.0
```

## ğŸ“ Estrutura do Projeto

```
project_MLxDL/
â”‚
â”œâ”€â”€ README.md                           # Este arquivo
â””â”€â”€ MLxDL.ipynb  # Notebook principal
```

## ğŸ” Principais SeÃ§Ãµes do Notebook

1. **ğŸ“¥ Carregamento dos Dados** - Oxford Flowers 102
2. **ğŸ”§ PreparaÃ§Ã£o dos Dados** - Redimensionamento para 64x64 e normalizaÃ§Ã£o
3. **ğŸ”— Modelo Dense NN** - ImplementaÃ§Ã£o baseada em 02_asl.ipynb
4. **ğŸ§  Modelo CNN** - ImplementaÃ§Ã£o baseada em 03_asl_cnn.ipynb
5. **ğŸ“Š ComparaÃ§Ã£o dos Resultados** - GrÃ¡ficos e anÃ¡lises detalhadas
6. **ğŸ¯ ConclusÃµes** - AnÃ¡lise dos resultados e liÃ§Ãµes aprendidas

## ğŸ’¡ AnÃ¡lise Detalhada dos Resultados

### âœ… Por que CNN Ã© Superior para Imagens:

**Dense Neural Network:**
- Trata cada pixel independentemente
- Ignora relaÃ§Ãµes espaciais entre pixels vizinhos
- Muitos parÃ¢metros desperdiÃ§ados
- Inadequado para dados com estrutura espacial

**Convolutional Neural Network:**
- Detecta padrÃµes locais com filtros convolucionais
- Preserva informaÃ§Ã£o espacial das imagens
- Compartilha parÃ¢metros (muito mais eficiente)
- Hierarquia de features: bordas â†’ texturas â†’ formas â†’ objetos

### ğŸ“Š NÃºmeros que Impressionam:
- **Performance**: CNN obteve o dobro da acurÃ¡cia no treino
- **EficiÃªncia**: CNN usa 7x menos parÃ¢metros
- **EspecializaÃ§Ã£o**: CNN foi projetada especificamente para imagens

### âš ï¸ Desafios Encontrados:
- **Overfitting**: Ambos modelos memorizaram treino mas nÃ£o generalizaram
- **Dataset pequeno**: 1020 imagens para 102 classes Ã© limitado
- **Alta complexidade**: 102 classes de flores Ã© muito desafiador

## ğŸ“ Contexto AcadÃªmico

Este projeto foi desenvolvido como parte da atividade que solicita:
> "Usar como base os notebooks apresentados em aula (02_asl.ipynb e 03_asl_cnn.ipynb) para classificar um dataset diferente do apresentado em aula e comparar a diferenÃ§a de performance dos modelos ao usar as abordagens de ML e DL no mesmo problema."

### ğŸ“š ConexÃ£o com os Notebooks Originais:
- **02_asl.ipynb**: Forneceu a arquitetura exata do Dense NN (Flatten â†’ Dense(512) â†’ Dense(512) â†’ Output)
- **03_asl_cnn.ipynb**: Forneceu a estrutura completa da CNN (Conv2D + BatchNorm + MaxPool)
- **AdaptaÃ§Ã£o**: MudanÃ§a de 24 classes (ASL) para 102 classes (flores) e input shape de (28,28,1) para (64,64,3)

## ğŸ¯ ConclusÃµes Finais

### ğŸ† HipÃ³tese Confirmada:
A CNN superou significativamente o Dense NN para classificaÃ§Ã£o de imagens, exatamente como esperado!

### âœ… LiÃ§Ãµes Aprendidas:
1. **Para imagens, sempre use CNN** ao invÃ©s de Dense NN
2. **Estrutura espacial importa** - pixels vizinhos tÃªm relaÃ§Ã£o
3. **EspecializaÃ§Ã£o vence generalizaÃ§Ã£o** - CNN > Dense para visÃ£o
4. **EficiÃªncia em parÃ¢metros** Ã© fundamental para modelos prÃ¡ticos

### ğŸš€ AplicaÃ§Ãµes PrÃ¡ticas:
Este resultado explica por que:
- **Google Photos** usa CNN para reconhecer objetos
- **Instagram** usa CNN para filtros e moderaÃ§Ã£o
- **Carros autÃ´nomos** usam CNN para visÃ£o computacional
- **Sistemas mÃ©dicos** usam CNN para anÃ¡lise de imagens

## ğŸ”¬ Melhorias Futuras

- [ ] **Data Augmentation** - RotaÃ§Ã£o, zoom, flip para reduzir overfitting
- [ ] **Transfer Learning** - Modelos prÃ©-treinados (ResNet, VGG)
- [ ] **Early Stopping** - Parar quando validaÃ§Ã£o parar de melhorar
- [ ] **RegularizaÃ§Ã£o adicional** - L1/L2, mais Dropout
- [ ] **Mais Ã©pocas** - Treinamento mais longo com paciÃªncia
- [ ] **Ensemble de modelos** - Combinar mÃºltiplas CNNs

## ğŸ‘¨â€ğŸ’» Autora

**Aline Acioly Nascimento**
- GitHub: [@aanasc4](https://github.com/aanasc4)
- LinkedIn: [Aline Acioly](https://www.linkedin.com/in/aline-acioly-9217a7306/)

